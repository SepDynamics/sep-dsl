// SEP DSL Batch Processing Demo
// Demonstrates parallel processing of multiple patterns

pattern batch_demo {
    print("=== Advanced Batch Processing Demo ===")
    
    // Define multiple patterns to process in parallel
    pattern_ids = ["sensor_1", "sensor_2", "sensor_3", "sensor_4", "sensor_5"]
    pattern_codes = [
        "measure_coherence(\"sensor_data_1\")",
        "measure_entropy(\"sensor_data_2\")", 
        "qfh_analyze(\"101010110\")",
        "measure_coherence(\"pattern_sample\")",
        "measure_entropy(\"noise_pattern\")"
    ]
    
    print("Processing", len(pattern_ids), "patterns in parallel...")
    
    // Basic batch processing (auto-detect threads)
    batch_result = process_batch(pattern_ids, pattern_codes)
    
    print("Batch processing completed!")
    print("Patterns processed:", batch_result["patterns_processed"])
    print("Patterns succeeded:", batch_result["patterns_succeeded"])
    print("Patterns failed:", batch_result["patterns_failed"])
    print("Total time (ms):", batch_result["total_time_ms"])
    print("Average time per pattern (ms):", batch_result["average_time_ms"])
    
    // Display individual results
    print("\n=== Individual Pattern Results ===")
    results = batch_result["results"]
    i = 0
    while (i < len(results)) {
        result = results[i]
        print("Pattern", result["pattern_id"] + ":")
        print("  Success:", result["success"])
        print("  Value:", result["value"])
        if (result["error"] != "") {
            print("  Error:", result["error"])
        }
        i = i + 1
    }
    
    // Advanced batch processing with custom configuration
    print("\n=== Advanced Batch with Custom Config ===")
    
    // Use 4 threads, batch size 2, fail fast enabled, 10 second timeout
    advanced_result = process_batch(pattern_ids, pattern_codes, null, 4, 2, true, 10.0)
    
    print("Advanced batch completed!")
    print("Total time with 4 threads:", advanced_result["total_time_ms"], "ms")
    
    // Performance comparison
    speedup = batch_result["total_time_ms"] / advanced_result["total_time_ms"]
    print("Performance with custom config: " + speedup + "x speedup")
    
    print("\n=== Large Batch Demo ===")
    
    // Create a larger batch to demonstrate scalability
    large_pattern_ids = []
    large_pattern_codes = []
    
    i = 0
    while (i < 20) {
        large_pattern_ids = append(large_pattern_ids, "pattern_" + i)
        
        // Alternate between different analysis types
        if (i < 7) {
            large_pattern_codes = append(large_pattern_codes, "measure_coherence(\"data_" + i + "\")")
        } else if (i < 14) {
            large_pattern_codes = append(large_pattern_codes, "measure_entropy(\"data_" + i + "\")")
        } else {
            large_pattern_codes = append(large_pattern_codes, "qfh_analyze(\"101010\")")
        }
        i = i + 1
    }
    
    print("Processing large batch of", len(large_pattern_ids), "patterns...")
    
    large_result = process_batch(large_pattern_ids, large_pattern_codes, null, 8, 5, false, 30.0)
    
    print("Large batch results:")
    print("  Processed:", large_result["patterns_processed"])
    print("  Succeeded:", large_result["patterns_succeeded"])
    print("  Failed:", large_result["patterns_failed"])
    print("  Total time:", large_result["total_time_ms"], "ms")
    print("  Throughput:", large_result["patterns_processed"] / (large_result["total_time_ms"] / 1000.0), "patterns/second")
    
    success_rate = (large_result["patterns_succeeded"] / large_result["patterns_processed"]) * 100
    print("  Success rate:", success_rate, "%")
    
    print("\n=== Batch Processing Demo Complete ===")
}
